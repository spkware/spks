{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from spks.raw import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks.utils import *\n",
    "from pathlib import Path\n",
    "folder = Path('/scratch/ks25_sorting_20230905_131941_tr9v')\n",
    "\n",
    "with open(folder/'params.py','r') as f:\n",
    "    params = f.read()\n",
    "params = params.split('\\n')\n",
    "for i,p in enumerate(params):\n",
    "    if p.startswith('dat_path'):\n",
    "        params[i] = \"dat_path = 'filtered_recording.ap.bin'\"\n",
    "with open(folder/'params.py','w') as f:\n",
    "    f.write(\"\\n\".join(params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedSpikes():\n",
    "    def __init__(self,folder, compute_raw_templates=True, remove_duplicate_spikes = True):\n",
    "        '''Object to access the spike sorting results in phy'''\n",
    "        if type(folder) in [str]:\n",
    "            folder = Path(folder)\n",
    "        self.folder = folder\n",
    "        # load spiketimes\n",
    "        self.spike_times = self._load_required('spike_times.npy')\n",
    "        # load each spike cluster number\n",
    "        self.clusters = self._load_required('spike_clusters.npy')\n",
    "        self.unique_clusters = np.sort(np.unique(self.clusters))\n",
    "        # load the channel locations\n",
    "        self.channel_positions =  self._load_optional('channel_positions.npy')\n",
    "        self.channel_map =  self._load_optional('channel_map.npy')\n",
    "        # Load the amplitudes used to fit the template\n",
    "        self.spike_template_amplitudes = self._load_optional('amplitudes.npy')\n",
    "        # load spike templates (which template was fitted) for each spike\n",
    "        self.spike_templates = self._load_optional('spike_templates.npy')\n",
    "        # load the templates used to extract the spikes\n",
    "        self.templates =  self._load_optional('templates.npy')\n",
    "        # load the whitening matrix (to correct for the data having been whitened)\n",
    "        self.whitening_matrix = self._load_optional('whitening_mat_inv.npy')\n",
    "        if not self.whitening_matrix is None:\n",
    "            self.whitening_matrix = self.whitening_matrix.T\n",
    "        self.cluster_groups = self._load_optional('cluster_group.tsv')\n",
    "\n",
    "        # compute the raw templates and the position of each cluster based on the template position\n",
    "        if compute_raw_templates:\n",
    "            self._compute_template_amplitudes()\n",
    "\n",
    "        if remove_duplicate_spikes:\n",
    "            self._remove_duplicate_spikes()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ''' returns the spiketimes for a set of clusters'''\n",
    "        if type(index) in [int,np.int64,np.int32]:\n",
    "            index = [index]\n",
    "        if type(index) in [slice]:\n",
    "            index = np.arange(*index.indices(len(self)))\n",
    "        sp = []\n",
    "        for iclu in self.unique_clusters[index]:\n",
    "            sp.append(self.spike_times[self.clusters == iclu])\n",
    "        if len(sp) == 1:\n",
    "            return sp[0]\n",
    "        else:\n",
    "            return sp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_clusters)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for iclu in self.unique_clusters:\n",
    "            yield self.spike_times[self.clusters == iclu]\n",
    "\n",
    "\n",
    "    def _remove_duplicate_spikes(self):\n",
    "        get_overlapping_spikes_indices(sp.spike_times,sp.clusters, sp.templates_raw, sp.channel_positions)\n",
    "    \n",
    "    def _compute_template_amplitudes(self):\n",
    "        self.templates_raw = None\n",
    "        self.templates_amplitude = None\n",
    "        self.templates_position = None\n",
    "        self.spike_amplitudes = None\n",
    "        self.spike_positions = None\n",
    "        \n",
    "        if (not self.templates is None and \n",
    "            not self.whitening_matrix is None and \n",
    "            not self.channel_positions is None):\n",
    "            # the raw templates are the dot product of the templates by the whitening matrix\n",
    "            self.templates_raw = np.dot(self.templates,self.whitening_matrix)\n",
    "            # compute the peak to peak of each template\n",
    "            templates_peak_to_peak = (self.templates_raw.max(axis = 1) - self.templates_raw.min(axis = 1))\n",
    "            # the amplitude of each template is the max of the peak difference for all channels\n",
    "            self.templates_amplitude = templates_peak_to_peak.max(axis=1)\n",
    "            # compute the center of mass (X,Y) of the templates\n",
    "            self.template_position = [templates_peak_to_peak*pos for pos in self.channel_positions.T]\n",
    "            self.template_position = np.vstack([np.sum(t,axis =1 )/np.sum(templates_peak_to_peak,axis = 1) \n",
    "                                                for t in self.template_position]).T\n",
    "            # get the spike positions and amplitudes from the average templates\n",
    "            self.spike_amplitudes = self.templates_amplitude[self.spike_templates]*self.spike_template_amplitudes\n",
    "            self.spike_positions = self.template_position[self.spike_templates,:].squeeze()\n",
    "\n",
    "    def _load_required(self,file):\n",
    "        path = self.folder / file\n",
    "        assert path.exists(), f'[SortedSpikes] - {path} doesnt exist'\n",
    "        return np.load(path)\n",
    "\n",
    "    def _load_optional(self,file):\n",
    "        path = self.folder / file\n",
    "        if path.exists():\n",
    "            if path.suffix == '.npy':\n",
    "                return np.load(path)\n",
    "            elif path.suffix == '.tsv':\n",
    "                return pd.read_csv(path,sep = '\\t')\n",
    "        return None\n",
    "\n",
    "    # class timestamps():\n",
    "    #     def __init__(self)\n",
    "\n",
    "sp = SortedSpikes(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos, peak = waveforms_position(sp.templates_raw,sp.channel_positions)\n",
    "peak_to_peak = (sp.templates_raw.max(axis = 1) - sp.templates_raw.min(axis = 1)).max(axis=1)\n",
    "\n",
    "###\n",
    "import pylab as plt\n",
    "%matplotlib widget\n",
    "plt.figure()\n",
    "plt.plot(sp.channel_positions[:,0],sp.channel_positions[:,1],'ko',color='lightgray')\n",
    "plt.scatter(pos[20,0],pos[20,1],30,peak_to_peak[20],alpha = 0.5,cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.plot(sp.channel_positions[peak[20],0],sp.channel_positions[peak[20],1],'x')\n",
    "from spks.viz import plot_footprints\n",
    "plot_footprints(sp.templates_raw[20],sp.channel_positions,gain=[5,0.3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp['unit selection','probe','shank','unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_clusters = sp.clusters\n",
    "spike_times = sp.spike_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.templates_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_overlapping_spikes_indices(sp.spike_times,sp.clusters, sp.templates_raw, sp.channel_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(folder.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks.sorting import run_ks25\n",
    "sessionfiles = ['/home/data/JC131/20230901_113844/ephys_g0/ephys_g0_imec0/ephys_g0_t0.imec0.ap.bin',\n",
    "                   '/home/data/JC131/20230901_115632/ephys_g1/ephys_g1_imec0/ephys_g1_t0.imec0.ap.bin']\n",
    "\n",
    "run_ks25(sessionfiles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
