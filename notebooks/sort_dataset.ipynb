{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks import *\n",
    "# from pathlib import Path\n",
    "folder = Path('/scratch/ks25_sorting_20230905_131941_tr9v')\n",
    "\n",
    "with open(folder/'params.py','r') as f:\n",
    "    params = f.read()\n",
    "params = params.split('\\n')\n",
    "for i,p in enumerate(params):\n",
    "    if p.startswith('dat_path'):\n",
    "        params[i] = \"dat_path = 'filtered_recording.ap.bin'\"\n",
    "with open(folder/'params.py','w') as f:\n",
    "    f.write(\"\\n\".join(params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from spks import *\n",
    "\n",
    "class Clusters():\n",
    "    def __init__(self,folder,spike_times = None, \n",
    "                spike_clusters = None,\n",
    "                channels_positions = None, compute_raw_templates=True):#, remove_duplicate_spikes = False):\n",
    "        '''Object to access the spike sorting results in phy'''\n",
    "        if type(folder) in [str]:\n",
    "            folder = Path(folder)\n",
    "        self.folder = folder\n",
    "        # load spiketimes\n",
    "        self.spike_times = self._load_required('spike_times.npy')\n",
    "        # load each spike cluster number\n",
    "        self.spike_clusters = self._load_required('spike_clusters.npy')\n",
    "        self.unique_clusters = np.sort(np.unique(self.spike_clusters))\n",
    "        # load the channel locations\n",
    "        self.channel_positions =  self._load_optional('channel_positions.npy')\n",
    "        self.channel_map =  self._load_optional('channel_map.npy')\n",
    "        # Load the amplitudes used to fit the template\n",
    "        self.spike_template_amplitudes = self._load_optional('amplitudes.npy')\n",
    "        # load spike templates (which template was fitted) for each spike\n",
    "        self.spike_templates = self._load_optional('spike_templates.npy')\n",
    "        # load the templates used to extract the spikes\n",
    "        self.templates =  self._load_optional('templates.npy')\n",
    "        # load the whitening matrix (to correct for the data having been whitened)\n",
    "        self.whitening_matrix = self._load_optional('whitening_mat_inv.npy')\n",
    "        if not self.whitening_matrix is None:\n",
    "            self.whitening_matrix = self.whitening_matrix.T\n",
    "        self.cluster_groups = self._load_optional('cluster_group.tsv')\n",
    "\n",
    "        # compute the raw templates and the position of each cluster based on the template position\n",
    "        if compute_raw_templates:\n",
    "            self._compute_template_amplitudes()\n",
    "\n",
    "        #if remove_duplicate_spikes:\n",
    "        #    self.remove_duplicate_spikes()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ''' returns the spiketimes for a set of clusters'''\n",
    "        if type(index) in [int,np.int64,np.int32]:\n",
    "            index = [index]\n",
    "        if type(index) in [slice]:\n",
    "            index = np.arange(*index.indices(len(self)))\n",
    "        sp = []\n",
    "        for iclu in self.unique_clusters[index]:\n",
    "            sp.append(self.spike_times[self.spike_clusters == iclu])\n",
    "        if len(sp) == 1:\n",
    "            return sp[0]\n",
    "        else:\n",
    "            return sp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_clusters)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for iclu in self.unique_clusters:\n",
    "            yield self.spike_times[self.spike_clusters == iclu]\n",
    "\n",
    "\n",
    "    def remove_duplicate_spikes(self,overwrite_phy = False):\n",
    "        from spks.postprocess import get_overlapping_spikes_indices\n",
    "        doubled = get_overlapping_spikes_indices(self.spike_times,self.spike_clusters, self.templates_raw, self.channel_positions)\n",
    "        if not len(doubled):\n",
    "            return\n",
    "        self.spike_times = np.delete(self.spike_times,doubled)\n",
    "        self.spike_clusters = np.delete(self.spike_clusters,doubled)\n",
    "        \n",
    "        if not self.spike_amplitudes is None:\n",
    "            self.spike_amplitudes = np.delete(self.spike_amplitudes,doubled)\n",
    "        if not self.spike_positions is None:\n",
    "            self.spike_positions = np.delete(self.spike_positions,doubled)\n",
    "        if not self.spike_templates is None:\n",
    "            self.spike_templates = np.delete(self.spike_templates,doubled)\n",
    "        if not self.spike_template_amplitudes is None:\n",
    "            self.spike_template_amplitudes = np.delete(self.spike_template_amplitudes,doubled)\n",
    "        if overwrite_phy:\n",
    "            self.export_phy(self.folder)\n",
    "\n",
    "    def export_phy(self,folder):\n",
    "        if type(folder) is str:\n",
    "            folder = Path(folder)\n",
    "        np.save(folder/'spike_times.npy',self.spike_times)\n",
    "        np.save(folder/'spike_clusters.npy',self.spike_clusters)\n",
    "        if not self.spike_template_amplitudes is None:\n",
    "            np.save(folder/'amplitudes.npy', self.spike_template_amplitudes)\n",
    "        if not self.spike_templates is None:\n",
    "            np.save(folder/'spike_templates.npy', self.spike_templates)\n",
    "    \n",
    "    def _compute_template_amplitudes(self):\n",
    "        self.templates_raw = None\n",
    "        self.templates_amplitude = None\n",
    "        self.templates_position = None\n",
    "        self.spike_amplitudes = None\n",
    "        self.spike_positions = None\n",
    "        if (not self.templates is None and \n",
    "            not self.whitening_matrix is None and \n",
    "            not self.channel_positions is None):\n",
    "            # the raw templates are the dot product of the templates by the whitening matrix\n",
    "            self.templates_raw = np.dot(self.templates,self.whitening_matrix)\n",
    "            # compute the peak to peak of each template\n",
    "            templates_peak_to_peak = (self.templates_raw.max(axis = 1) - self.templates_raw.min(axis = 1))\n",
    "            # the amplitude of each template is the max of the peak difference for all channels\n",
    "            self.templates_amplitude = templates_peak_to_peak.max(axis=1)\n",
    "            # compute the center of mass (X,Y) of the templates\n",
    "            self.template_position = [templates_peak_to_peak*pos for pos in self.channel_positions.T]\n",
    "            self.template_position = np.vstack([np.sum(t,axis =1 )/np.sum(templates_peak_to_peak,axis = 1) \n",
    "                                                for t in self.template_position]).T\n",
    "            # get the spike positions and amplitudes from the average templates\n",
    "            self.spike_amplitudes = self.templates_amplitude[self.spike_templates]*self.spike_template_amplitudes\n",
    "            self.spike_positions = self.template_position[self.spike_templates,:].squeeze()\n",
    "\n",
    "    def _load_required(self,file,var = None):\n",
    "        path = self.folder / file\n",
    "        assert path.exists(), f'[SortedSpikes] - {path} doesnt exist'\n",
    "        return np.load(path)\n",
    "\n",
    "    def _load_optional(self,file):\n",
    "        path = self.folder / file\n",
    "        if path.exists():\n",
    "            if path.suffix == '.npy':\n",
    "                return np.load(path)\n",
    "            elif path.suffix == '.tsv':\n",
    "                return pd.read_csv(path,sep = '\\t')\n",
    "        return None\n",
    "\n",
    "    # class timestamps():\n",
    "    #     def __init__(self)\n",
    "\n",
    "folder = Path('/scratch/ks25_sorting_20230905_131941_tr9v')\n",
    "\n",
    "sp = Clusters(folder,remove_duplicate_spikes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# folder\n",
    "dat2 = map_binary(folder/'filtered_recording.ap.bin',meta['nchannels'])\n",
    "meta = load_dict_from_h5(folder/'filtered_recording.ap.metadata.hdf')\n",
    "meta['file_offsets'],dat.file_sample_offsets,dat.shape,dat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = Path('/scratch/ks25_sorting_20230905_131941_tr9v')\n",
    "sessionfiles = ['/home/data/JC131/20230901_113844/ephys_g0/ephys_g0_imec0/ephys_g0_t0.imec0.ap.bin',\n",
    "                '/home/data/JC131/20230901_115632/ephys_g1/ephys_g1_imec0/ephys_g1_t0.imec0.ap.bin']\n",
    "\n",
    "dat = RawRecording(sessionfiles,return_preprocessed = False)\n",
    "\n",
    "meta = load_dict_from_h5(folder/'filtered_recording.ap.metadata.hdf')\n",
    "dat2 = map_binary(folder/'filtered_recording.ap.bin',meta['nchannels'])\n",
    "\n",
    "sp = Clusters(folder)\n",
    "\n",
    "mwaves = extract_waveform_set(spike_times = sp,data = dat2,chmap = dat.channel_info.channel_idx.values,max_n_spikes=1000, chunksize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = {}\n",
    "for iclu,w in zip(sp.unique_clusters,mwaves):\n",
    "    waveforms[iclu] = w\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "save_dict_to_h5(folder/'cluster_waveforms.hdf',waveforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "waveforms = load_dict_from_h5(folder/'cluster_waveforms.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget \n",
    "import pylab as plt\n",
    "from spks import *\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "iclus = 200\n",
    "for mw in mwaves[iclus][:20]:\n",
    "    plot_footprints(waves = ,\n",
    "                    channel_xy = np.stack(dat.channel_info.channel_coord.values), gain=[15,0.07],lw = 0.1);\n",
    "\n",
    "plot_footprints(waves = mwaves[iclus].mean(axis=0),\n",
    "                    channel_xy = np.stack(dat.channel_info.channel_coord.values), gain=[15,0.07],lw = 1,color = 'r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos, peak = waveforms_position(sp.templates_raw,sp.channel_positions)\n",
    "peak_to_peak = (sp.templates_raw.max(axis = 1) - sp.templates_raw.min(axis = 1)).max(axis=1)\n",
    "\n",
    "###\n",
    "import pylab as plt\n",
    "%matplotlib widget\n",
    "plt.figure()\n",
    "plt.plot(sp.channel_positions[:,0],sp.channel_positions[:,1],'o',color='lightgray')\n",
    "plt.scatter(pos[20,0],pos[20,1],30,peak_to_peak[20],alpha = 0.5,cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.plot(sp.channel_positions[peak[20],0],sp.channel_positions[peak[20],1],'x')\n",
    "from spks.viz import plot_footprints\n",
    "plot_footprints(sp.templates_raw[20],sp.channel_positions,gain=[5,0.3]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp['unit selection','probe','shank','unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_clusters = sp.clusters\n",
    "spike_times = sp.spike_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.templates_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_overlapping_spikes_indices(sp.spike_times,sp.clusters, sp.templates_raw, sp.channel_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(folder.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks.sorting import run_ks25\n",
    "sessionfiles = ['/home/data/JC131/20230901_113844/ephys_g0/ephys_g0_imec0/ephys_g0_t0.imec0.ap.bin',\n",
    "                   '/home/data/JC131/20230901_115632/ephys_g1/ephys_g1_imec0/ephys_g1_t0.imec0.ap.bin']\n",
    "\n",
    "run_ks25(sessionfiles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
